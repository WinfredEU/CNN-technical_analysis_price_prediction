{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import weatherdataprocesstool as wt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>dewp</th>\n",
       "      <th>slp</th>\n",
       "      <th>stp</th>\n",
       "      <th>visib</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>mxpsd</th>\n",
       "      <th>prcp</th>\n",
       "      <th>extremeClimate</th>\n",
       "      <th>SOI</th>\n",
       "      <th>ONI</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-10-01</th>\n",
       "      <td>67.330699</td>\n",
       "      <td>56.341969</td>\n",
       "      <td>1017.285733</td>\n",
       "      <td>979.701295</td>\n",
       "      <td>11.318394</td>\n",
       "      <td>5.287306</td>\n",
       "      <td>11.164637</td>\n",
       "      <td>0.031371</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-11-01</th>\n",
       "      <td>54.260477</td>\n",
       "      <td>43.621330</td>\n",
       "      <td>1015.895226</td>\n",
       "      <td>977.766248</td>\n",
       "      <td>11.421832</td>\n",
       "      <td>5.924718</td>\n",
       "      <td>11.954969</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.983797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-12-01</th>\n",
       "      <td>41.714267</td>\n",
       "      <td>31.840078</td>\n",
       "      <td>1017.545467</td>\n",
       "      <td>978.890260</td>\n",
       "      <td>11.840726</td>\n",
       "      <td>8.000259</td>\n",
       "      <td>14.519844</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-01-01</th>\n",
       "      <td>25.787829</td>\n",
       "      <td>17.198116</td>\n",
       "      <td>1023.084000</td>\n",
       "      <td>983.486575</td>\n",
       "      <td>11.571016</td>\n",
       "      <td>7.946801</td>\n",
       "      <td>13.848306</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.005982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-02-01</th>\n",
       "      <td>22.852830</td>\n",
       "      <td>14.027799</td>\n",
       "      <td>1021.799742</td>\n",
       "      <td>982.012704</td>\n",
       "      <td>11.186164</td>\n",
       "      <td>6.846667</td>\n",
       "      <td>12.952645</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-03-01</th>\n",
       "      <td>32.402921</td>\n",
       "      <td>24.998470</td>\n",
       "      <td>1019.129429</td>\n",
       "      <td>979.907510</td>\n",
       "      <td>9.660918</td>\n",
       "      <td>7.220862</td>\n",
       "      <td>13.298609</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-04-01</th>\n",
       "      <td>40.157519</td>\n",
       "      <td>31.178446</td>\n",
       "      <td>1014.458452</td>\n",
       "      <td>975.835589</td>\n",
       "      <td>10.910902</td>\n",
       "      <td>9.037218</td>\n",
       "      <td>15.921053</td>\n",
       "      <td>0.064238</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-05-01</th>\n",
       "      <td>45.475259</td>\n",
       "      <td>33.169171</td>\n",
       "      <td>1012.028400</td>\n",
       "      <td>973.695071</td>\n",
       "      <td>11.852461</td>\n",
       "      <td>9.083290</td>\n",
       "      <td>16.227591</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>1.423077</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.058629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-06-01</th>\n",
       "      <td>57.168844</td>\n",
       "      <td>43.326005</td>\n",
       "      <td>1016.872387</td>\n",
       "      <td>978.883794</td>\n",
       "      <td>12.759422</td>\n",
       "      <td>8.053266</td>\n",
       "      <td>15.010553</td>\n",
       "      <td>0.051431</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.035054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-07-01</th>\n",
       "      <td>68.743717</td>\n",
       "      <td>55.221204</td>\n",
       "      <td>1014.510807</td>\n",
       "      <td>977.133333</td>\n",
       "      <td>12.513351</td>\n",
       "      <td>6.706937</td>\n",
       "      <td>12.989005</td>\n",
       "      <td>0.032442</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.014072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-08-01</th>\n",
       "      <td>73.495597</td>\n",
       "      <td>61.436352</td>\n",
       "      <td>1014.966493</td>\n",
       "      <td>977.729785</td>\n",
       "      <td>12.065912</td>\n",
       "      <td>6.012704</td>\n",
       "      <td>12.214969</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.827297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-09-01</th>\n",
       "      <td>72.495506</td>\n",
       "      <td>61.674157</td>\n",
       "      <td>1017.868129</td>\n",
       "      <td>980.619157</td>\n",
       "      <td>10.718976</td>\n",
       "      <td>5.172160</td>\n",
       "      <td>10.929588</td>\n",
       "      <td>0.023221</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.228940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-10-01</th>\n",
       "      <td>65.866624</td>\n",
       "      <td>55.481830</td>\n",
       "      <td>1016.804272</td>\n",
       "      <td>979.297625</td>\n",
       "      <td>11.444072</td>\n",
       "      <td>6.839691</td>\n",
       "      <td>12.942397</td>\n",
       "      <td>0.073230</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.812959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-11-01</th>\n",
       "      <td>54.454806</td>\n",
       "      <td>43.278901</td>\n",
       "      <td>1018.055097</td>\n",
       "      <td>980.051403</td>\n",
       "      <td>11.723845</td>\n",
       "      <td>6.781398</td>\n",
       "      <td>12.793883</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>1.115385</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-12-01</th>\n",
       "      <td>40.015335</td>\n",
       "      <td>31.909665</td>\n",
       "      <td>1019.316310</td>\n",
       "      <td>980.613342</td>\n",
       "      <td>10.723067</td>\n",
       "      <td>6.792268</td>\n",
       "      <td>12.573969</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>1.346154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.204328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-01</th>\n",
       "      <td>26.933292</td>\n",
       "      <td>20.345318</td>\n",
       "      <td>1018.270801</td>\n",
       "      <td>979.075638</td>\n",
       "      <td>9.533915</td>\n",
       "      <td>7.170324</td>\n",
       "      <td>13.005860</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.819635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-02-01</th>\n",
       "      <td>20.759634</td>\n",
       "      <td>13.257439</td>\n",
       "      <td>1021.356072</td>\n",
       "      <td>981.673657</td>\n",
       "      <td>9.837683</td>\n",
       "      <td>8.236220</td>\n",
       "      <td>14.405250</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.984142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-03-01</th>\n",
       "      <td>27.399069</td>\n",
       "      <td>20.460771</td>\n",
       "      <td>1017.922031</td>\n",
       "      <td>978.808911</td>\n",
       "      <td>8.689495</td>\n",
       "      <td>8.160239</td>\n",
       "      <td>14.302660</td>\n",
       "      <td>0.027694</td>\n",
       "      <td>1.074074</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.081517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-04-01</th>\n",
       "      <td>34.944418</td>\n",
       "      <td>25.803721</td>\n",
       "      <td>1017.038625</td>\n",
       "      <td>978.569098</td>\n",
       "      <td>9.818247</td>\n",
       "      <td>8.399760</td>\n",
       "      <td>14.454382</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.984224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-05-01</th>\n",
       "      <td>48.968944</td>\n",
       "      <td>33.798012</td>\n",
       "      <td>1017.249359</td>\n",
       "      <td>979.356907</td>\n",
       "      <td>12.440621</td>\n",
       "      <td>8.492795</td>\n",
       "      <td>15.706708</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.015138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-06-01</th>\n",
       "      <td>66.656543</td>\n",
       "      <td>52.625330</td>\n",
       "      <td>1014.427826</td>\n",
       "      <td>977.383887</td>\n",
       "      <td>11.811525</td>\n",
       "      <td>8.346579</td>\n",
       "      <td>15.202881</td>\n",
       "      <td>0.073157</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.131228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-07-01</th>\n",
       "      <td>69.648139</td>\n",
       "      <td>57.558561</td>\n",
       "      <td>1015.744602</td>\n",
       "      <td>978.779974</td>\n",
       "      <td>11.938710</td>\n",
       "      <td>6.215509</td>\n",
       "      <td>12.228696</td>\n",
       "      <td>0.039763</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.827388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-08-01</th>\n",
       "      <td>72.600360</td>\n",
       "      <td>60.584154</td>\n",
       "      <td>1015.172671</td>\n",
       "      <td>978.360907</td>\n",
       "      <td>12.206002</td>\n",
       "      <td>5.825570</td>\n",
       "      <td>11.768547</td>\n",
       "      <td>0.051990</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-09-01</th>\n",
       "      <td>72.812695</td>\n",
       "      <td>59.064910</td>\n",
       "      <td>1015.186286</td>\n",
       "      <td>978.390655</td>\n",
       "      <td>12.238802</td>\n",
       "      <td>6.004431</td>\n",
       "      <td>12.092575</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.990698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-10-01</th>\n",
       "      <td>62.461042</td>\n",
       "      <td>51.983995</td>\n",
       "      <td>1017.249166</td>\n",
       "      <td>979.990494</td>\n",
       "      <td>11.914764</td>\n",
       "      <td>5.915509</td>\n",
       "      <td>11.573789</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.008451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-11-01</th>\n",
       "      <td>55.555222</td>\n",
       "      <td>45.522329</td>\n",
       "      <td>1016.038828</td>\n",
       "      <td>978.499878</td>\n",
       "      <td>11.352821</td>\n",
       "      <td>6.455222</td>\n",
       "      <td>12.350900</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.200745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-01</th>\n",
       "      <td>40.620370</td>\n",
       "      <td>31.634938</td>\n",
       "      <td>1020.238395</td>\n",
       "      <td>981.936173</td>\n",
       "      <td>10.400741</td>\n",
       "      <td>6.242716</td>\n",
       "      <td>11.799877</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.005661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-01-01</th>\n",
       "      <td>26.753708</td>\n",
       "      <td>18.564593</td>\n",
       "      <td>1020.400599</td>\n",
       "      <td>981.449461</td>\n",
       "      <td>9.639474</td>\n",
       "      <td>7.202392</td>\n",
       "      <td>12.907923</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.875164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-02-01</th>\n",
       "      <td>16.713023</td>\n",
       "      <td>8.634409</td>\n",
       "      <td>1021.187305</td>\n",
       "      <td>981.744671</td>\n",
       "      <td>9.407168</td>\n",
       "      <td>7.166189</td>\n",
       "      <td>12.525269</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.044934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-03-01</th>\n",
       "      <td>23.534656</td>\n",
       "      <td>13.574339</td>\n",
       "      <td>1019.076821</td>\n",
       "      <td>980.143841</td>\n",
       "      <td>10.233862</td>\n",
       "      <td>7.718122</td>\n",
       "      <td>14.032937</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.980607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>27.840831</td>\n",
       "      <td>22.052337</td>\n",
       "      <td>1016.417367</td>\n",
       "      <td>976.716732</td>\n",
       "      <td>7.975255</td>\n",
       "      <td>7.794597</td>\n",
       "      <td>14.519661</td>\n",
       "      <td>0.047627</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.038749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>35.326358</td>\n",
       "      <td>25.826594</td>\n",
       "      <td>1014.587695</td>\n",
       "      <td>974.775068</td>\n",
       "      <td>9.143817</td>\n",
       "      <td>8.371043</td>\n",
       "      <td>15.841176</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.966623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>37.805361</td>\n",
       "      <td>26.932607</td>\n",
       "      <td>1020.529260</td>\n",
       "      <td>981.319414</td>\n",
       "      <td>9.092286</td>\n",
       "      <td>9.141053</td>\n",
       "      <td>16.793644</td>\n",
       "      <td>0.062671</td>\n",
       "      <td>1.349901</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.023020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>51.510744</td>\n",
       "      <td>40.423822</td>\n",
       "      <td>1014.519311</td>\n",
       "      <td>975.887628</td>\n",
       "      <td>9.352175</td>\n",
       "      <td>8.407738</td>\n",
       "      <td>16.199622</td>\n",
       "      <td>0.094455</td>\n",
       "      <td>0.389328</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.981469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>58.044036</td>\n",
       "      <td>46.241382</td>\n",
       "      <td>1011.679331</td>\n",
       "      <td>973.402604</td>\n",
       "      <td>9.492083</td>\n",
       "      <td>7.830042</td>\n",
       "      <td>15.625321</td>\n",
       "      <td>0.101529</td>\n",
       "      <td>1.258000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.039461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>69.739575</td>\n",
       "      <td>56.082018</td>\n",
       "      <td>1012.175114</td>\n",
       "      <td>974.221366</td>\n",
       "      <td>9.763313</td>\n",
       "      <td>7.005315</td>\n",
       "      <td>15.005986</td>\n",
       "      <td>0.072598</td>\n",
       "      <td>0.191235</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.940630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>73.318451</td>\n",
       "      <td>63.382964</td>\n",
       "      <td>1015.469431</td>\n",
       "      <td>977.780310</td>\n",
       "      <td>9.535125</td>\n",
       "      <td>5.401006</td>\n",
       "      <td>12.326563</td>\n",
       "      <td>0.074648</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>68.295481</td>\n",
       "      <td>59.566465</td>\n",
       "      <td>1016.350727</td>\n",
       "      <td>978.481083</td>\n",
       "      <td>9.350834</td>\n",
       "      <td>5.049955</td>\n",
       "      <td>11.503667</td>\n",
       "      <td>0.072417</td>\n",
       "      <td>0.432540</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.989444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>65.430616</td>\n",
       "      <td>55.242730</td>\n",
       "      <td>1016.727799</td>\n",
       "      <td>978.517086</td>\n",
       "      <td>9.335973</td>\n",
       "      <td>5.719216</td>\n",
       "      <td>12.195452</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.990754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>54.137293</td>\n",
       "      <td>43.770007</td>\n",
       "      <td>1016.054413</td>\n",
       "      <td>977.046421</td>\n",
       "      <td>9.371524</td>\n",
       "      <td>7.844882</td>\n",
       "      <td>15.197364</td>\n",
       "      <td>0.090465</td>\n",
       "      <td>0.501969</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.030151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>38.792832</td>\n",
       "      <td>29.638177</td>\n",
       "      <td>1018.699816</td>\n",
       "      <td>979.071643</td>\n",
       "      <td>9.056614</td>\n",
       "      <td>7.813557</td>\n",
       "      <td>15.068199</td>\n",
       "      <td>0.039105</td>\n",
       "      <td>0.652008</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.984669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>25.793053</td>\n",
       "      <td>17.143580</td>\n",
       "      <td>1019.893605</td>\n",
       "      <td>979.957284</td>\n",
       "      <td>8.894139</td>\n",
       "      <td>8.013623</td>\n",
       "      <td>15.133557</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.067061</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.024062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>22.559824</td>\n",
       "      <td>14.936680</td>\n",
       "      <td>1023.202777</td>\n",
       "      <td>983.029607</td>\n",
       "      <td>8.703850</td>\n",
       "      <td>8.345905</td>\n",
       "      <td>15.104430</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.280230</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>1.046994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>26.389292</td>\n",
       "      <td>18.874932</td>\n",
       "      <td>1021.732839</td>\n",
       "      <td>981.877716</td>\n",
       "      <td>8.590345</td>\n",
       "      <td>7.980991</td>\n",
       "      <td>15.162915</td>\n",
       "      <td>0.068125</td>\n",
       "      <td>0.541426</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1.022442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>35.396417</td>\n",
       "      <td>25.256691</td>\n",
       "      <td>1018.650988</td>\n",
       "      <td>979.351851</td>\n",
       "      <td>9.097283</td>\n",
       "      <td>8.317863</td>\n",
       "      <td>15.292404</td>\n",
       "      <td>0.043250</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.024532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>41.132817</td>\n",
       "      <td>28.566557</td>\n",
       "      <td>1017.581829</td>\n",
       "      <td>978.686197</td>\n",
       "      <td>9.163958</td>\n",
       "      <td>8.515033</td>\n",
       "      <td>16.245508</td>\n",
       "      <td>0.047586</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.986767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-01</th>\n",
       "      <td>66.466186</td>\n",
       "      <td>53.385716</td>\n",
       "      <td>1013.917097</td>\n",
       "      <td>975.659841</td>\n",
       "      <td>9.354544</td>\n",
       "      <td>6.509827</td>\n",
       "      <td>14.399896</td>\n",
       "      <td>0.096142</td>\n",
       "      <td>0.593291</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.886335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-01</th>\n",
       "      <td>71.778542</td>\n",
       "      <td>61.418548</td>\n",
       "      <td>1012.483306</td>\n",
       "      <td>974.607312</td>\n",
       "      <td>9.432968</td>\n",
       "      <td>6.548259</td>\n",
       "      <td>14.082267</td>\n",
       "      <td>0.118823</td>\n",
       "      <td>0.548035</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.051873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>73.511835</td>\n",
       "      <td>63.456486</td>\n",
       "      <td>1017.215994</td>\n",
       "      <td>979.370830</td>\n",
       "      <td>9.535756</td>\n",
       "      <td>5.105111</td>\n",
       "      <td>11.865829</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.962637</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01</th>\n",
       "      <td>72.096327</td>\n",
       "      <td>63.873400</td>\n",
       "      <td>1015.241526</td>\n",
       "      <td>977.128400</td>\n",
       "      <td>9.007888</td>\n",
       "      <td>5.133218</td>\n",
       "      <td>11.775915</td>\n",
       "      <td>0.098806</td>\n",
       "      <td>0.785249</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>66.047676</td>\n",
       "      <td>57.954980</td>\n",
       "      <td>1017.886466</td>\n",
       "      <td>979.532347</td>\n",
       "      <td>9.299786</td>\n",
       "      <td>5.921874</td>\n",
       "      <td>12.566328</td>\n",
       "      <td>0.110252</td>\n",
       "      <td>1.043764</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>49.741260</td>\n",
       "      <td>41.567562</td>\n",
       "      <td>1018.060886</td>\n",
       "      <td>978.855697</td>\n",
       "      <td>9.059103</td>\n",
       "      <td>6.826283</td>\n",
       "      <td>13.885529</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.805252</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.041581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>33.133604</td>\n",
       "      <td>26.620787</td>\n",
       "      <td>1019.032656</td>\n",
       "      <td>979.071959</td>\n",
       "      <td>8.779453</td>\n",
       "      <td>7.236044</td>\n",
       "      <td>13.741392</td>\n",
       "      <td>0.058992</td>\n",
       "      <td>0.415755</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.983639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>30.811408</td>\n",
       "      <td>25.297252</td>\n",
       "      <td>1018.879391</td>\n",
       "      <td>978.697294</td>\n",
       "      <td>8.446534</td>\n",
       "      <td>6.871855</td>\n",
       "      <td>13.246713</td>\n",
       "      <td>0.055501</td>\n",
       "      <td>1.640969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.006653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>21.834156</td>\n",
       "      <td>15.384583</td>\n",
       "      <td>1020.296195</td>\n",
       "      <td>980.415453</td>\n",
       "      <td>8.386206</td>\n",
       "      <td>8.133336</td>\n",
       "      <td>15.340956</td>\n",
       "      <td>0.042432</td>\n",
       "      <td>0.689162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.986120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>22.999200</td>\n",
       "      <td>16.852798</td>\n",
       "      <td>1020.159917</td>\n",
       "      <td>980.139904</td>\n",
       "      <td>7.737231</td>\n",
       "      <td>8.129454</td>\n",
       "      <td>15.349137</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>0.487755</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.969839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>32.860447</td>\n",
       "      <td>23.979106</td>\n",
       "      <td>1020.738079</td>\n",
       "      <td>981.189008</td>\n",
       "      <td>8.928992</td>\n",
       "      <td>7.885454</td>\n",
       "      <td>15.043178</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.407186</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.018659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>48.674711</td>\n",
       "      <td>37.464525</td>\n",
       "      <td>1014.219676</td>\n",
       "      <td>975.344556</td>\n",
       "      <td>9.198373</td>\n",
       "      <td>8.234179</td>\n",
       "      <td>16.251454</td>\n",
       "      <td>0.072887</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.151289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>57.527019</td>\n",
       "      <td>48.551720</td>\n",
       "      <td>1013.537219</td>\n",
       "      <td>975.032919</td>\n",
       "      <td>9.245598</td>\n",
       "      <td>7.125647</td>\n",
       "      <td>14.744158</td>\n",
       "      <td>0.149830</td>\n",
       "      <td>1.044266</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.979375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>67.910556</td>\n",
       "      <td>57.116141</td>\n",
       "      <td>1013.317071</td>\n",
       "      <td>975.238854</td>\n",
       "      <td>9.470414</td>\n",
       "      <td>6.221417</td>\n",
       "      <td>13.922837</td>\n",
       "      <td>0.102907</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.945247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temp       dewp          slp         stp      visib  \\\n",
       "date2                                                                  \n",
       "1960-10-01  67.330699  56.341969  1017.285733  979.701295  11.318394   \n",
       "1960-11-01  54.260477  43.621330  1015.895226  977.766248  11.421832   \n",
       "1960-12-01  41.714267  31.840078  1017.545467  978.890260  11.840726   \n",
       "1961-01-01  25.787829  17.198116  1023.084000  983.486575  11.571016   \n",
       "1961-02-01  22.852830  14.027799  1021.799742  982.012704  11.186164   \n",
       "1961-03-01  32.402921  24.998470  1019.129429  979.907510   9.660918   \n",
       "1961-04-01  40.157519  31.178446  1014.458452  975.835589  10.910902   \n",
       "1961-05-01  45.475259  33.169171  1012.028400  973.695071  11.852461   \n",
       "1961-06-01  57.168844  43.326005  1016.872387  978.883794  12.759422   \n",
       "1961-07-01  68.743717  55.221204  1014.510807  977.133333  12.513351   \n",
       "1961-08-01  73.495597  61.436352  1014.966493  977.729785  12.065912   \n",
       "1961-09-01  72.495506  61.674157  1017.868129  980.619157  10.718976   \n",
       "1961-10-01  65.866624  55.481830  1016.804272  979.297625  11.444072   \n",
       "1961-11-01  54.454806  43.278901  1018.055097  980.051403  11.723845   \n",
       "1961-12-01  40.015335  31.909665  1019.316310  980.613342  10.723067   \n",
       "1962-01-01  26.933292  20.345318  1018.270801  979.075638   9.533915   \n",
       "1962-02-01  20.759634  13.257439  1021.356072  981.673657   9.837683   \n",
       "1962-03-01  27.399069  20.460771  1017.922031  978.808911   8.689495   \n",
       "1962-04-01  34.944418  25.803721  1017.038625  978.569098   9.818247   \n",
       "1962-05-01  48.968944  33.798012  1017.249359  979.356907  12.440621   \n",
       "1962-06-01  66.656543  52.625330  1014.427826  977.383887  11.811525   \n",
       "1962-07-01  69.648139  57.558561  1015.744602  978.779974  11.938710   \n",
       "1962-08-01  72.600360  60.584154  1015.172671  978.360907  12.206002   \n",
       "1962-09-01  72.812695  59.064910  1015.186286  978.390655  12.238802   \n",
       "1962-10-01  62.461042  51.983995  1017.249166  979.990494  11.914764   \n",
       "1962-11-01  55.555222  45.522329  1016.038828  978.499878  11.352821   \n",
       "1962-12-01  40.620370  31.634938  1020.238395  981.936173  10.400741   \n",
       "1963-01-01  26.753708  18.564593  1020.400599  981.449461   9.639474   \n",
       "1963-02-01  16.713023   8.634409  1021.187305  981.744671   9.407168   \n",
       "1963-03-01  23.534656  13.574339  1019.076821  980.143841  10.233862   \n",
       "...               ...        ...          ...         ...        ...   \n",
       "2017-02-01  27.840831  22.052337  1016.417367  976.716732   7.975255   \n",
       "2017-03-01  35.326358  25.826594  1014.587695  974.775068   9.143817   \n",
       "2017-04-01  37.805361  26.932607  1020.529260  981.319414   9.092286   \n",
       "2017-05-01  51.510744  40.423822  1014.519311  975.887628   9.352175   \n",
       "2017-06-01  58.044036  46.241382  1011.679331  973.402604   9.492083   \n",
       "2017-07-01  69.739575  56.082018  1012.175114  974.221366   9.763313   \n",
       "2017-08-01  73.318451  63.382964  1015.469431  977.780310   9.535125   \n",
       "2017-09-01  68.295481  59.566465  1016.350727  978.481083   9.350834   \n",
       "2017-10-01  65.430616  55.242730  1016.727799  978.517086   9.335973   \n",
       "2017-11-01  54.137293  43.770007  1016.054413  977.046421   9.371524   \n",
       "2017-12-01  38.792832  29.638177  1018.699816  979.071643   9.056614   \n",
       "2018-01-01  25.793053  17.143580  1019.893605  979.957284   8.894139   \n",
       "2018-02-01  22.559824  14.936680  1023.202777  983.029607   8.703850   \n",
       "2018-03-01  26.389292  18.874932  1021.732839  981.877716   8.590345   \n",
       "2018-04-01  35.396417  25.256691  1018.650988  979.351851   9.097283   \n",
       "2018-05-01  41.132817  28.566557  1017.581829  978.686197   9.163958   \n",
       "2018-06-01  66.466186  53.385716  1013.917097  975.659841   9.354544   \n",
       "2018-07-01  71.778542  61.418548  1012.483306  974.607312   9.432968   \n",
       "2018-08-01  73.511835  63.456486  1017.215994  979.370830   9.535756   \n",
       "2018-09-01  72.096327  63.873400  1015.241526  977.128400   9.007888   \n",
       "2018-10-01  66.047676  57.954980  1017.886466  979.532347   9.299786   \n",
       "2018-11-01  49.741260  41.567562  1018.060886  978.855697   9.059103   \n",
       "2018-12-01  33.133604  26.620787  1019.032656  979.071959   8.779453   \n",
       "2019-01-01  30.811408  25.297252  1018.879391  978.697294   8.446534   \n",
       "2019-02-01  21.834156  15.384583  1020.296195  980.415453   8.386206   \n",
       "2019-03-01  22.999200  16.852798  1020.159917  980.139904   7.737231   \n",
       "2019-04-01  32.860447  23.979106  1020.738079  981.189008   8.928992   \n",
       "2019-05-01  48.674711  37.464525  1014.219676  975.344556   9.198373   \n",
       "2019-06-01  57.527019  48.551720  1013.537219  975.032919   9.245598   \n",
       "2019-07-01  67.910556  57.116141  1013.317071  975.238854   9.470414   \n",
       "\n",
       "                wdsp      mxpsd      prcp  extremeClimate  SOI  ONI    return  \n",
       "date2                                                                          \n",
       "1960-10-01  5.287306  11.164637  0.031371        0.730769  0.7  0.3  0.986713  \n",
       "1960-11-01  5.924718  11.954969  0.026902        0.076923  0.1  0.2  0.983797  \n",
       "1960-12-01  8.000259  14.519844  0.012274        0.880000  0.5  0.1  0.917801  \n",
       "1961-01-01  7.946801  13.848306  0.012076        0.346154  0.8  0.1  1.005982  \n",
       "1961-02-01  6.846667  12.952645  0.002955        1.440000 -0.3  0.0  1.002932  \n",
       "1961-03-01  7.220862  13.298609  0.021860        0.692308  0.9  0.0  1.005929  \n",
       "1961-04-01  9.037218  15.921053  0.064238        0.807692 -1.8  0.0  0.952931  \n",
       "1961-05-01  9.083290  16.227591  0.053155        1.423077  0.8  0.1  1.058629  \n",
       "1961-06-01  8.053266  15.010553  0.051431        0.760000  0.3  0.2  1.035054  \n",
       "1961-07-01  6.706937  12.989005  0.032442        1.269231  0.1  0.3  1.014072  \n",
       "1961-08-01  6.012704  12.214969  0.058182        0.576923  0.2  0.1  0.827297  \n",
       "1961-09-01  5.172160  10.929588  0.023221        1.640000  0.2 -0.1  1.228940  \n",
       "1961-10-01  6.839691  12.942397  0.073230        1.538462  0.1 -0.3  0.812959  \n",
       "1961-11-01  6.781398  12.793883  0.035899        1.115385 -0.3 -0.3  1.001845  \n",
       "1961-12-01  6.792268  12.573969  0.032046        1.346154  0.5 -0.2  1.204328  \n",
       "1962-01-01  7.170324  13.005860  0.019565        0.807692  1.5 -0.2  0.819635  \n",
       "1962-02-01  8.236220  14.405250  0.022474        0.960000  2.0 -0.2  0.984142  \n",
       "1962-03-01  8.160239  14.302660  0.027694        1.074074 -0.3 -0.2  1.081517  \n",
       "1962-04-01  8.399760  14.454382  0.020018        0.481481  0.1 -0.2  0.984224  \n",
       "1962-05-01  8.492795  15.706708  0.019147        1.111111  0.2 -0.3  1.015138  \n",
       "1962-06-01  8.346579  15.202881  0.073157        1.555556  1.1 -0.3  1.131228  \n",
       "1962-07-01  6.215509  12.228696  0.039763        1.185185  0.7 -0.2  0.827388  \n",
       "1962-08-01  5.825570  11.768547  0.051990        0.555556  0.1  0.0  1.007498  \n",
       "1962-09-01  6.004431  12.092575  0.038055        0.222222  0.6 -0.1  0.990698  \n",
       "1962-10-01  5.915509  11.573789  0.035302        0.814815  0.4 -0.1  1.008451  \n",
       "1962-11-01  6.455222  12.350900  0.019065        0.923077  1.0 -0.2  1.200745  \n",
       "1962-12-01  6.242716  11.799877  0.009485        0.629630  0.3 -0.3  1.005661  \n",
       "1963-01-01  7.202392  12.907923  0.006089        0.333333  0.2 -0.4  0.875164  \n",
       "1963-02-01  7.166189  12.525269  0.009222        0.851852  1.0 -0.4  1.044934  \n",
       "1963-03-01  7.718122  14.032937  0.007564        1.666667  0.6 -0.2  0.980607  \n",
       "...              ...        ...       ...             ...  ...  ...       ...  \n",
       "2017-02-01  7.794597  14.519661  0.047627        0.214286  0.2 -0.3  1.038749  \n",
       "2017-03-01  8.371043  15.841176  0.023625        0.573123 -0.1 -0.1  0.966623  \n",
       "2017-04-01  9.141053  16.793644  0.062671        1.349901  0.9  0.1  1.023020  \n",
       "2017-05-01  8.407738  16.199622  0.094455        0.389328 -0.2  0.3  0.981469  \n",
       "2017-06-01  7.830042  15.625321  0.101529        1.258000  0.3  0.4  1.039461  \n",
       "2017-07-01  7.005315  15.005986  0.072598        0.191235 -0.4  0.4  0.940630  \n",
       "2017-08-01  5.401006  12.326563  0.074648        0.623016  0.8  0.2  0.980000  \n",
       "2017-09-01  5.049955  11.503667  0.072417        0.432540  0.5 -0.1  0.989444  \n",
       "2017-10-01  5.719216  12.195452  0.043840        0.335938  0.6 -0.4  0.990754  \n",
       "2017-11-01  7.844882  15.197364  0.090465        0.501969  0.9 -0.7  1.030151  \n",
       "2017-12-01  7.813557  15.068199  0.039105        0.652008  0.9 -0.9  0.984669  \n",
       "2018-01-01  8.013623  15.133557  0.018778        0.067061 -0.1 -1.0  1.024062  \n",
       "2018-02-01  8.345905  15.104430  0.021311        0.280230  1.1 -0.9  1.046994  \n",
       "2018-03-01  7.980991  15.162915  0.068125        0.541426 -0.5 -0.8  1.022442  \n",
       "2018-04-01  8.317863  15.292404  0.043250        0.607692  1.5 -0.6  1.024532  \n",
       "2018-05-01  8.515033  16.245508  0.047586        0.550000  0.5 -0.4  0.986767  \n",
       "2018-06-01  6.509827  14.399896  0.096142        0.593291  0.4 -0.1  0.886335  \n",
       "2018-07-01  6.548259  14.082267  0.118823        0.548035 -0.1  0.1  1.051873  \n",
       "2018-08-01  5.105111  11.865829  0.076111        0.962637  0.2  0.1  1.002055  \n",
       "2018-09-01  5.133218  11.775915  0.098806        0.785249 -0.3  0.2  1.000000  \n",
       "2018-10-01  5.921874  12.566328  0.110252        1.043764 -0.9  0.4  1.002734  \n",
       "2018-11-01  6.826283  13.885529  0.089661        0.805252  0.4  0.7  1.041581  \n",
       "2018-12-01  7.236044  13.741392  0.058992        0.415755 -0.1  0.9  0.983639  \n",
       "2019-01-01  6.871855  13.246713  0.055501        1.640969  1.0  0.8  1.006653  \n",
       "2019-02-01  8.133336  15.340956  0.042432        0.689162  0.0  0.8  0.986120  \n",
       "2019-03-01  8.129454  15.349137  0.062637        0.487755 -1.4  0.8  0.969839  \n",
       "2019-04-01  7.885454  15.043178  0.057490        0.407186 -0.3  0.8  1.018659  \n",
       "2019-05-01  8.234179  16.251454  0.072887        0.262000  0.1  0.8  1.151289  \n",
       "2019-06-01  7.125647  14.744158  0.149830        1.044266 -0.4  0.6  0.979375  \n",
       "2019-07-01  6.221417  13.922837  0.102907        0.789474 -0.5  0.5  0.945247  \n",
       "\n",
       "[706 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_pickle('/Users/benbilly3/Desktop/資策會專題/rawMaterialPricePrediction/US_Weather/US_weather_cornsArea_traindata.pickle')\n",
    "dataset=dataset.drop(columns='win')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(706, 12)\n",
      "(706, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(dataset.shape)\n",
    "dataset = dataset.dropna(thresh=int(len(dataset)*0.5), axis=1).dropna(how='any')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>dewp</th>\n",
       "      <th>slp</th>\n",
       "      <th>stp</th>\n",
       "      <th>visib</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>mxpsd</th>\n",
       "      <th>prcp</th>\n",
       "      <th>extremeClimate</th>\n",
       "      <th>SOI</th>\n",
       "      <th>ONI</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-10-01</th>\n",
       "      <td>67.330699</td>\n",
       "      <td>56.341969</td>\n",
       "      <td>1017.285733</td>\n",
       "      <td>979.701295</td>\n",
       "      <td>11.318394</td>\n",
       "      <td>5.287306</td>\n",
       "      <td>11.164637</td>\n",
       "      <td>0.031371</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-11-01</th>\n",
       "      <td>54.260477</td>\n",
       "      <td>43.621330</td>\n",
       "      <td>1015.895226</td>\n",
       "      <td>977.766248</td>\n",
       "      <td>11.421832</td>\n",
       "      <td>5.924718</td>\n",
       "      <td>11.954969</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.983797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-12-01</th>\n",
       "      <td>41.714267</td>\n",
       "      <td>31.840078</td>\n",
       "      <td>1017.545467</td>\n",
       "      <td>978.890260</td>\n",
       "      <td>11.840726</td>\n",
       "      <td>8.000259</td>\n",
       "      <td>14.519844</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.917801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-01-01</th>\n",
       "      <td>25.787829</td>\n",
       "      <td>17.198116</td>\n",
       "      <td>1023.084000</td>\n",
       "      <td>983.486575</td>\n",
       "      <td>11.571016</td>\n",
       "      <td>7.946801</td>\n",
       "      <td>13.848306</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.005982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-02-01</th>\n",
       "      <td>22.852830</td>\n",
       "      <td>14.027799</td>\n",
       "      <td>1021.799742</td>\n",
       "      <td>982.012704</td>\n",
       "      <td>11.186164</td>\n",
       "      <td>6.846667</td>\n",
       "      <td>12.952645</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.002932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temp       dewp          slp         stp      visib  \\\n",
       "date2                                                                  \n",
       "1960-10-01  67.330699  56.341969  1017.285733  979.701295  11.318394   \n",
       "1960-11-01  54.260477  43.621330  1015.895226  977.766248  11.421832   \n",
       "1960-12-01  41.714267  31.840078  1017.545467  978.890260  11.840726   \n",
       "1961-01-01  25.787829  17.198116  1023.084000  983.486575  11.571016   \n",
       "1961-02-01  22.852830  14.027799  1021.799742  982.012704  11.186164   \n",
       "\n",
       "                wdsp      mxpsd      prcp  extremeClimate  SOI  ONI    return  \n",
       "date2                                                                          \n",
       "1960-10-01  5.287306  11.164637  0.031371        0.730769  0.7  0.3  0.986713  \n",
       "1960-11-01  5.924718  11.954969  0.026902        0.076923  0.1  0.2  0.983797  \n",
       "1960-12-01  8.000259  14.519844  0.012274        0.880000  0.5  0.1  0.917801  \n",
       "1961-01-01  7.946801  13.848306  0.012076        0.346154  0.8  0.1  1.005982  \n",
       "1961-02-01  6.846667  12.952645  0.002955        1.440000 -0.3  0.0  1.002932  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_arr = dataset.index.get_level_values('date2') < '2008'\n",
    "dataset_train = dataset[date_arr]\n",
    "dataset_test = dataset[~date_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9928057553956835"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cf = RandomForestClassifier(n_estimators=5)\n",
    "\n",
    "train = dataset_train[feature_names] , dataset_train['return'] > 1 \n",
    "test = dataset_test[feature_names] , dataset_test['return'] > 1 \n",
    "\n",
    "cf.fit(*train)\n",
    "cf.score(*test)\n",
    "# cf.predict(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9928057553956835"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "cf_xgb = xgboost.XGBClassifier()\n",
    "cf_xgb.fit(*train)\n",
    "cf_xgb.score(*test)\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm\n",
    "\n",
    "## 自動調整參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.998337\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.987734\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.995218\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.995738\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989293\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998649\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.997817\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989813\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.999064\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.995842\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989917\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.99896\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.998337\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.99657\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.996881\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.994595\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.997817\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.996674\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990333\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.997089\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.99948\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997505\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.988046\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.999376\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.998233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.995946\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.994075\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.997089\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.990644\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.997297\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.99553\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.988254\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997817\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.996466\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.990437\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.999064\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's auc: 0.992516\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's auc: 0.989189\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid's auc: 0.99605\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's auc: 0.997921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.991268\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.998545\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.998857\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.990541\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.997921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.997505\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990541\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998129\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.995218\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.989605\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's auc: 0.994802\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.997921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.989605\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.995114\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.996985\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990852\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.99605\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's auc: 0.997297\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.989501\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.996881\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid's auc: 0.995842\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid's auc: 0.988358\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.997297\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.994595\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.997817\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.998857\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.990541\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.997713\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid's auc: 0.997401\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990541\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.994179\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid's auc: 0.998545\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid's auc: 0.9921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid's auc: 0.997713\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998129\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989813\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998233\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.992204\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.991268\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993555\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.997921\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.988773\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid's auc: 0.999168\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998857\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990644\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998129\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.993659\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.995738\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.996466\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.992723\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid's auc: 0.997297\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998753\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990644\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998233\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.996778\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989085\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997713\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid's auc: 0.999168\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989813\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.995634\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.994595\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989813\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.99106\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.991476\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.990644\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.996674\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.994802\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.998857\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.99657\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.990644\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.996466\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.997713\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.999168\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.998649\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid's auc: 0.997401\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.989605\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.999064\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid's auc: 0.99896\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.996778\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.5\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.996258\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.989397\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997297\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid's auc: 0.996674\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.988565\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.997817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.998753\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid's auc: 0.99553\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid's auc: 0.998753\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid's auc: 0.998337\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid's auc: 0.993243\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid's auc: 0.998129\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        metric='None', min_child_samples=20, min_child_weight=0.001,\n",
       "        min_split_gain=0.0, n_estimators=5000, n_jobs=4, num_leaves=31,\n",
       "        objective=None, random_state=314, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
       "          param_distributions={'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object at 0x12193d518>, 'min_child_samples': <scipy.stats._distn_infrastructure.rv_frozen object at 0x12193d6a0>, 'min_child_weight': [1e-05, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0, 10000.0], 'subsample': <scipy.stats....eb8>, 'reg_alpha': [0, 0.1, 1, 2, 5, 7, 10, 50, 100], 'reg_lambda': [0, 0.1, 1, 5, 10, 20, 50, 100]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "\n",
    "fit_params={\"early_stopping_rounds\":10, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [test],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}#fit參數\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 20), \n",
    "             'min_child_samples': sp_randint(10, 50), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, \n",
    "    param_distributions=param_test,#枚舉調參 \n",
    "    n_iter=n_HP_points_to_test,#幾種model?\n",
    "    scoring='roc_auc',#模型評斷標準\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=1,\n",
    "    verbose=True)\n",
    "\n",
    "gs.fit(*train, **fit_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找出最佳參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.8111317002380557, importance_type='split',\n",
       "        learning_rate=0.1, max_depth=-1, metric='None',\n",
       "        min_child_samples=21, min_child_weight=0.01, min_split_gain=0.0,\n",
       "        n_estimators=5000, n_jobs=4, num_leaves=10, objective=None,\n",
       "        random_state=314, reg_alpha=50, reg_lambda=100, silent=True,\n",
       "        subsample=0.6469518627566013, subsample_for_bin=200000,\n",
       "        subsample_freq=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid's auc: 0.993243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9928057553956835"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cf_lgbm = lightgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
    "        colsample_bytree=0.8111317002380557, importance_type='split',\n",
    "        learning_rate=0.1, max_depth=-1, metric='None',\n",
    "        min_child_samples=21, min_child_weight=0.01, min_split_gain=0.0,\n",
    "        n_estimators=5000, n_jobs=4, num_leaves=10, objective=None,\n",
    "        random_state=314, reg_alpha=50, reg_lambda=100, silent=True,\n",
    "        subsample=0.6469518627566013, subsample_for_bin=200000,\n",
    "        subsample_freq=0)\n",
    "cf_lgbm.fit(dataset_train[feature_names],dataset_train['return'] > 1, **fit_params)\n",
    "cf_lgbm.score(dataset_test[feature_names],dataset_test['return'] > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54562658, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.46849841, 0.46849841, 0.46849841, 0.46849841,\n",
       "       0.46849841, 0.54562658, 0.46849841, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.54562658, 0.46849841, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.46849841, 0.54562658, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.46849841, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.46849841, 0.54562658, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.54562658, 0.46849841, 0.54562658, 0.54562658,\n",
       "       0.54562658, 0.46849841, 0.46849841, 0.46849841, 0.46849841,\n",
       "       0.54562658, 0.46849841, 0.46849841, 0.54562658, 0.46849841,\n",
       "       0.46849841, 0.46849841, 0.54562658, 0.46849841, 0.46849841,\n",
       "       0.46849841, 0.54562658, 0.54562658, 0.54562658, 0.54562658,\n",
       "       0.46849841, 0.46849841, 0.46849841, 0.46849841, 0.54562658,\n",
       "       0.46849841, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.54562658, 0.46849841, 0.46849841, 0.54562658,\n",
       "       0.46849841, 0.46849841, 0.54562658, 0.46849841, 0.46849841,\n",
       "       0.46849841, 0.54562658, 0.46849841, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.46849841, 0.46849841, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.46849841, 0.54562658, 0.54562658, 0.54562658,\n",
       "       0.46849841, 0.54562658, 0.46849841, 0.54562658, 0.46849841,\n",
       "       0.46849841, 0.46849841, 0.46849841, 0.54562658, 0.46849841,\n",
       "       0.54562658, 0.54562658, 0.54562658, 0.54562658, 0.46849841,\n",
       "       0.46849841, 0.54562658, 0.54562658, 0.46849841, 0.54562658,\n",
       "       0.54562658, 0.46849841, 0.54562658, 0.46849841, 0.46849841,\n",
       "       0.54562658, 0.54562658, 0.46849841, 0.46849841])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = gs.predict_proba(test[0])\n",
    "#prediction = cf_lgbm.predict_proba(test[0])\n",
    "\n",
    "prediction = prediction.swapaxes(0,1)[1]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12184cd68>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "returns = dataset_test['return'][prediction > 0.5]\n",
    "dates = returns.index.get_level_values(\"date2\")\n",
    "returns.groupby(dates).mean().cumprod().plot(color='red')\n",
    "\n",
    "returns = dataset_test['return'][prediction < 0.5]\n",
    "dates = returns.index.get_level_values(\"date2\")\n",
    "returns.groupby(dates).mean().cumprod().plot(color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finlab",
   "language": "python",
   "name": "finlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
